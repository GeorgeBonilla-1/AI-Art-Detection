{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577bf2c1c41fc600",
   "metadata": {},
   "source": [
    "# AI vs Human Art ML Project\n",
    "### Step 1: Data Loading\n",
    "\n",
    "We still need to check if this is the correct way to load the data..(we can ask professor if this is correct)\n",
    "Also you need to load the data from your own machine after you download it(having it on git is not good apparently)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Imports\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd979b90b1a5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"data/train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    label_mode = \"binary\",\n",
    "    image_size=(512, 512), # All the images in the dataset are this size\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"data/train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    label_mode = \"binary\",\n",
    "    image_size=(512, 512),\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef8a7536a70abb",
   "metadata": {},
   "source": [
    "# Step 2: EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513e31152386b41",
   "metadata": {},
   "source": [
    "print(\"heelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb7651b-ef31-4799-a254-ae6b84c870b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d037ee58-2114-49a8-bac3-0689a074f728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
