{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AI vs Human Art ML Project\n",
    "\n",
    "\n",
    "Introduction: This notebook our submission for our Machine Learning final project. This project aims to use image classification to predict AI art or human art images.\n",
    "\n",
    "### Step 1: Data Loading\n",
    "\n",
    "\n"
   ],
   "id": "2d76c37a5421e1b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T19:34:36.503478Z",
     "start_time": "2025-12-07T19:34:34.385489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pathlib\n",
    "\n",
    "# import all the required packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pathlib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ],
   "id": "d49fbcd2aaa72858",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m classification_report,confusion_matrix\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mrandom\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcv2\u001B[39;00m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'cv2'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Loading the Training Data:\n",
    "The training data and test data must be loaded differently as the train folder has the typical structure of having subfolders for the 2 classes. The test folder doesn't have any subfolders so the images are not divided by their classes."
   ],
   "id": "fae39827f5c4dfa6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Loading the training data\n",
    "labels = ['AI_GENERATED', 'NON_AI_GENERATED']\n",
    "img_size = 224\n",
    "\n",
    "# File path to the training data\n",
    "data_dir = pathlib.Path('data')\n",
    "\n",
    "# Function to load the the data(training data)\n",
    "\n",
    "def get_train_data()"
   ],
   "id": "71321858692ffdb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Rewriting the way the data is loaded\n",
    "labels = ['AI_GENERATED', 'NON_AI_GENERATED']\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "def get_file_paths(data_dir):\n",
    "    \"\"\"Get all file paths and labels without loading images\"\"\"\n",
    "    file_paths = []\n",
    "    file_labels = []\n",
    "\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "\n",
    "        for img in os.listdir(path):\n",
    "            img_path = os.path.join(path, img)\n",
    "            file_paths.append(img_path)\n",
    "            file_labels.append(class_num)\n",
    "\n",
    "    return file_paths, file_labels\n",
    "\n",
    "def data_generator(file_paths, file_labels, batch_size=32, shuffle=True):\n",
    "    \"\"\"Generator that yields batches of images and labels\"\"\"\n",
    "    indices = np.arange(len(file_paths))\n",
    "\n",
    "    while True:  # Loop forever for Keras\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "        for start_idx in range(0, len(file_paths), batch_size):\n",
    "            batch_indices = indices[start_idx:start_idx + batch_size]\n",
    "\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "\n",
    "            for idx in batch_indices:\n",
    "                try:\n",
    "                    img_arr = cv2.imread(file_paths[idx])[...,::-1]  # BGR to RGB\n",
    "                    if img_arr is None:\n",
    "                        continue\n",
    "                    resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                    normalized = resized_arr.astype(np.float32) / 255.0\n",
    "\n",
    "                    batch_images.append(normalized)\n",
    "                    batch_labels.append(file_labels[idx])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_paths[idx]}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            if len(batch_images) > 0:\n",
    "                yield np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "def get_test_file_paths(data_dir):\n",
    "    \"\"\"Get all test file paths without loading images\"\"\"\n",
    "    file_paths = []\n",
    "\n",
    "    for img in os.listdir(data_dir):\n",
    "        img_path = os.path.join(data_dir, img)\n",
    "        if os.path.isfile(img_path):\n",
    "            file_paths.append(img_path)\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "def test_data_generator(file_paths, batch_size=32):\n",
    "    \"\"\"Generator for test data without labels\"\"\"\n",
    "    for start_idx in range(0, len(file_paths), batch_size):\n",
    "        batch_paths = file_paths[start_idx:start_idx + batch_size]\n",
    "        batch_images = []\n",
    "\n",
    "        for img_path in batch_paths:\n",
    "            try:\n",
    "                img_arr = cv2.imread(img_path)[...,::-1]  # BGR to RGB\n",
    "                if img_arr is None:\n",
    "                    continue\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                normalized = resized_arr.astype(np.float32) / 255.0\n",
    "                batch_images.append(normalized)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if len(batch_images) > 0:\n",
    "            yield np.array(batch_images)"
   ],
   "id": "a55fc349892c9fd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_paths, train_labels = get_file_paths('data/train')\n",
    "print(f\"Total training images: {len(train_paths)}\")\n",
    "\n",
    "# Get test file paths\n",
    "test_paths = get_test_file_paths('data/test')\n",
    "print(f\"Test samples: {len(test_paths)}\")\n",
    "train_gen = data_generator(train_paths, train_labels, batch_size=batch_size, shuffle=True)\n",
    "test_gen = test_data_generator(test_paths, batch_size=batch_size)\n"
   ],
   "id": "73ef219394dd550f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2: Visualize the data",
   "id": "e585e56e0303620"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "l = []\n",
    "for label in train_labels:\n",
    "    if(label == 0):\n",
    "        l.append(\"AI_GENERATED\")\n",
    "    else:\n",
    "        l.append(\"NON_AI_GENERATED\")\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(x=l)"
   ],
   "id": "56beefac586540bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imbalanced data :(",
   "id": "8b5d0447f108d1a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "\n",
    "# Get one random AI image\n",
    "ai_indices = [i for i, label in enumerate(train_labels) if label == 0]\n",
    "ai_idx = random.choice(ai_indices)\n",
    "\n",
    "img_ai = cv2.imread(train_paths[ai_idx])[...,::-1]\n",
    "img_ai = cv2.resize(img_ai, (img_size, img_size))\n",
    "\n",
    "# Display AI image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img_ai)\n",
    "plt.title(labels[0])\n",
    "plt.show()\n",
    "\n",
    "# Get one random Real image\n",
    "real_indices = [i for i, label in enumerate(train_labels) if label == 1]\n",
    "real_idx = random.choice(real_indices)\n",
    "\n",
    "img_real = cv2.imread(train_paths[real_idx])[...,::-1]\n",
    "img_real = cv2.resize(img_real, (img_size, img_size))\n",
    "\n",
    "# Display Real image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img_real)\n",
    "plt.title(labels[1])\n",
    "\n",
    "plt.show()"
   ],
   "id": "c1ac6c69e12955ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preview_images(file_paths, file_labels, num_images=5):\n",
    "    \"\"\"Preview random images from both classes\"\"\"\n",
    "\n",
    "    # Separate indices by class\n",
    "    ai_indices = [i for i, label in enumerate(file_labels) if label == 0]  # AI_GENERATED\n",
    "    real_indices = [i for i, label in enumerate(file_labels) if label == 1]  # NON_AI_GENERATED\n",
    "\n",
    "    print(f\"Total AI Generated images: {len(ai_indices)}\")\n",
    "    print(f\"Total Non-AI Generated images: {len(real_indices)}\")\n",
    "\n",
    "    # Sample random indices\n",
    "    ai_sample_indices = random.sample(ai_indices, min(num_images, len(ai_indices)))\n",
    "    real_sample_indices = random.sample(real_indices, min(num_images, len(real_indices)))\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(15, 6))\n",
    "    fig.suptitle('Image Preview: AI vs Non-AI Generated', fontsize=16)\n",
    "\n",
    "    # Load and plot AI generated images\n",
    "    for i, idx in enumerate(ai_sample_indices):\n",
    "        img = cv2.imread(file_paths[idx])[...,::-1]  # BGR to RGB\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_title('AI Generated', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Load and plot Non-AI generated images\n",
    "    for i, idx in enumerate(real_sample_indices):\n",
    "        img = cv2.imread(file_paths[idx])[...,::-1]  # BGR to RGB\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        axes[1, i].imshow(img)\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_title('Non-AI Generated', fontsize=12, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Preview 5 images from each class\n",
    "preview_images(train_paths, train_labels, num_images=5)"
   ],
   "id": "177ba19236e5d5c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2: Data Preprocessing and Data Augmentation",
   "id": "94358a5f99be614c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Split file paths into train and validation (80/20 split)\n",
    "train_paths_split, val_paths, train_labels_split, val_labels = train_test_split(\n",
    "    train_paths, train_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_labels\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_paths_split)}\")\n",
    "print(f\"Validation samples: {len(val_paths)}\")\n",
    "print(f\"Test samples: {len(test_paths)}\")\n",
    "\n",
    "# ========== ADD DATA AUGMENTATION ==========\n",
    "# Create augmentation object for training\n",
    "augmentor = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Modified generator WITH augmentation for training\n",
    "def augmented_data_generator(file_paths, file_labels, batch_size=32, shuffle=True, augment=True):\n",
    "    \"\"\"Generator with optional data augmentation\"\"\"\n",
    "    indices = np.arange(len(file_paths))\n",
    "\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "        for start_idx in range(0, len(file_paths), batch_size):\n",
    "            batch_indices = indices[start_idx:start_idx + batch_size]\n",
    "\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "\n",
    "            for idx in batch_indices:\n",
    "                try:\n",
    "                    img_arr = cv2.imread(file_paths[idx])[...,::-1]  # BGR to RGB\n",
    "                    if img_arr is None:\n",
    "                        continue\n",
    "                    resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                    normalized = resized_arr.astype(np.float32) / 255.0\n",
    "\n",
    "                    batch_images.append(normalized)\n",
    "                    batch_labels.append(file_labels[idx])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_paths[idx]}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            if len(batch_images) > 0:\n",
    "                batch_images = np.array(batch_images)\n",
    "                batch_labels = np.array(batch_labels)\n",
    "\n",
    "                # Apply augmentation only if requested\n",
    "                if augment:\n",
    "                    aug_gen = augmentor.flow(batch_images, batch_labels, batch_size=len(batch_images), shuffle=False)\n",
    "                    batch_images, batch_labels = next(aug_gen)\n",
    "\n",
    "                yield batch_images, batch_labels\n",
    "\n",
    "# Create generators\n",
    "batch_size = 32\n",
    "\n",
    "# Training generator WITH augmentation\n",
    "train_gen = augmented_data_generator(train_paths_split, train_labels_split, batch_size=batch_size, shuffle=True, augment=True)\n",
    "\n",
    "# Validation generator WITHOUT augmentation\n",
    "val_gen = augmented_data_generator(val_paths, val_labels, batch_size=batch_size, shuffle=False, augment=False)\n",
    "\n",
    "# Test generator (no labels, no augmentation)\n",
    "test_gen = test_data_generator(test_paths, batch_size=batch_size)\n",
    "\n",
    "# Calculate steps for training\n",
    "steps_per_epoch = len(train_paths_split) // batch_size\n",
    "validation_steps = len(val_paths) // batch_size\n",
    "test_steps = len(test_paths) // batch_size + 1  # +1 to include remaining images\n",
    "\n",
    "print(f\"\\nSteps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n",
    "print(f\"Test steps: {test_steps}\")"
   ],
   "id": "28b6bdac896b8cb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 3: Define the model",
   "id": "6de82c3536f2970e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ],
   "id": "87f5f7de947edf77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # For integer labels (0, 1)\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "id": "9fb1b0fe3ba0987a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")"
   ],
   "id": "a735000d16f18433"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 4: Train the Model",
   "id": "7636e4cf35564ab5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 5: Evaluating the Result",
   "id": "d22a17f3745f7385"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "plt.title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)"
   ],
   "id": "49015b286081892d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)"
   ],
   "id": "2f5f0eba93f5b2f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ========== 2. Print Final Metrics ==========\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL TRAINING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training Accuracy:   {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "print(f\"Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
    "print(f\"Training Loss:       {final_train_loss:.4f}\")\n",
    "print(f\"Validation Loss:     {final_val_loss:.4f}\")\n",
    "print(\"=\"*50)"
   ],
   "id": "47b84e7a77a6e216"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ========== 3. Evaluate on Validation Set ==========\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "val_loss, val_accuracy = model.evaluate(val_gen, steps=validation_steps, verbose=1)\n",
    "print(f\"\\nValidation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n"
   ],
   "id": "6c0e7f77b57c629d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ========== 4. Make Predictions on Test Set ==========\n",
    "print(\"\\nMaking predictions on test set...\")\n",
    "predictions = model.predict(test_gen, steps=test_steps, verbose=1)\n",
    "\n",
    "# Get predicted classes\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "confidence_scores = np.max(predictions, axis=1)\n",
    "\n",
    "print(f\"\\nTotal test predictions: {len(predicted_classes)}\")\n",
    "print(f\"Predicted as AI_GENERATED: {np.sum(predicted_classes == 0)} ({np.sum(predicted_classes == 0)/len(predicted_classes)*100:.1f}%)\")\n",
    "print(f\"Predicted as NON_AI_GENERATED: {np.sum(predicted_classes == 1)} ({np.sum(predicted_classes == 1)/len(predicted_classes)*100:.1f}%)\")\n",
    "print(f\"Average confidence: {np.mean(confidence_scores):.2%}\")"
   ],
   "id": "d320360e895918e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ========== 5. Show Sample Predictions ==========\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SAMPLE TEST PREDICTIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get a few random test images\n",
    "sample_indices = np.random.choice(len(test_paths), min(10, len(test_paths)), replace=False)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    pred_class = predicted_classes[idx]\n",
    "    confidence = confidence_scores[idx]\n",
    "    print(f\"\\nImage: {os.path.basename(test_paths[idx])}\")\n",
    "    print(f\"  Predicted: {labels[pred_class]}\")\n",
    "    print(f\"  Confidence: {confidence:.2%}\")\n"
   ],
   "id": "8ea26e6941cd22ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ========== 5. Show Sample Predictions ==========\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SAMPLE TEST PREDICTIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get a few random test images\n",
    "sample_indices = np.random.choice(len(test_paths), min(10, len(test_paths)), replace=False)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    pred_class = predicted_classes[idx]\n",
    "    confidence = confidence_scores[idx]\n",
    "    print(f\"\\nImage: {os.path.basename(test_paths[idx])}\")\n",
    "    print(f\"  Predicted: {labels[pred_class]}\")\n",
    "    print(f\"  Confidence: {confidence:.2%}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4230080af5e9daa3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eac9fce7fc82e6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
